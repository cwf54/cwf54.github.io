<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Jambot</title>
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Varela+Round" rel="stylesheet" />
        <link href="https://fonts.googleapis.com/css?family=Nunito:200,200i,300,300i,400,400i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
            <div class="container px-4 px-lg-5">
                <a class="navbar-brand" href="#page-top">Fast Robots</a>
                <button class="navbar-toggler navbar-toggler-right" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto">
                        <li class="nav-item"><a class="nav-link" href="#about">Welcome</a></li>
                        <li class="nav-item"><a class="nav-link" href="#projects">Lab 1</a></li>
                        <!-- <li class="nav-item"><a class="nav-link" href="#design">Software and Hardware Design</a></li>
                        <li class="nav-item"><a class="nav-link" href="#results">Results</a></li>
                        <li class="nav-item"><a class="nav-link" href="#conclusion">Conclusion</a></li>
                        <li class="nav-item"><a class="nav-link" href="#demo">Demo!</a></li>
                        <li class="nav-item"><a class="nav-link" href="#appendices">Appendices</a></li> -->



                        <!-- <li class="nav-item"><a class="nav-link" href="#signup">Contact</a></li> -->
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <header class="masthead">
            <div class="container px-4 px-lg-5 d-flex h-100 align-items-center justify-content-center">
                <div class="d-flex justify-content-center">
                    <div class="text-center">
                        <h1 class="mx-auto my-0 text-uppercase">Fast Robots</h1>
                        <h2 class="text-white-50 mx-auto mt-2 mb-5">ECE 4160 Spring 2023</h2>
                        <!-- <a class="btn btn-primary" href="#about">Get Started</a> -->

                        
                    </div>
                </div>
            </div>
        </header>

        <section class="about-section text-center" id="names">
            <!-- <div class="container px-4 px-lg-5"> -->
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-lg-8">
                        <!-- <h4 class="text-white mb-4"> </h4>
                        <h4 class="text-white mb-4">ECE 4760 F22 Final Project </h4> -->
                    </div>
                </div>
            <!-- </div> -->
        </section>
        <!-- About-->
        <section class="about-section text-center" id="about">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-lg-8">
                        <h2 class="text-white mb-4">Wanda Field</h2>

                        <p class="text-white-50">
                        Hello! I am a senior in ECE at Cornell interested in firmware and embedded systems. This website will contain updates and overviews of 
                        all of the labs for ECE 4160.
                        </p>
                    </div>
                </div>
                <img class="img-fluid" src="assets/img/headshot.jfif" alt="..." width="527" height="428"/> 
            </div>
        </section>
        <!-- Projects-->
        <section class="projects-section bg-light" id="projects">
            <div class="container px-4 px-lg-5">
                <!-- Featured Project Row-->
                <div class="row gx-0 mb-4 mb-lg-5 align-items-center">
                        <div class="featured-text text-center text-lg-left">
                            <h2>Lab 1: Introduction to the Redboard Artemis Nano</h2>
                            <p class="text-black-50 mb-0">
                                This first lab served to help become familiar with the Artemis board and 
                                uploading Arduino programs to it. After setting up the Arduino IDE on a lab computer, 
                                I ran 4 pre-written example programs on the board.    
                            </p>
                            
                            <img class="img-fluid" src="assets/img/artemis.jpg" alt="..." /></div>

                            
                            <h4>Example Program 1: Blinking Light</h4>
                            <p class="text-black-50 mb-0">The simplest program to run on any board is blinking an LED. 
                                Similar to outputting "Hello World," this program ensures that the system is set up properly.</p>
                                <!-- <img class="img-fluid" src="assets/img/serial_monitor.PNG" alt="..." />  -->
                            </p>
                            <h4>Example Program 2: Serial Monitor</h4>
                            <p class="text-black-50 mb-0">This next example tests the serial communication feature of the board. 
                                Upon running this program, a series of print statements appear in the Serial Monitor.
                            </p>
                            <h4>Example Program 3: Analog Read
                            </h4>
                            <p class="text-black-50 mb-0">Now testing the onboard testing sensor. Notice how in the beginning of the video, 
                                the temperature values are in the 32,200 count range. After I press my thumb onto the board, heating it up, 
                                the temperature increases to the 32,600 count range. After I release my thumb, the temperature drops back down to 32,200 counts.
                            </p>
                            <h4>Example Program 4: PDM</h4>
                            <p class="text-black-50 mb-0">The final example tests the microphone capabilities of the board. The Serial Monitor prints out the 
                                frequency the microphone detects, and when I whistle into the microphone, the frequency skyrockets to the 2000 Hz range.
                            </p>
                                <!-- <img class="img-fluid" src="assets/img/serial_monitor.PNG" alt="..." />  -->

                                
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Design -->
        <!-- <section class="about-section text-center" id="design">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-lg-8">
                        <h2 class="text-white mb-4">Software and Hardware Designs</h2>
                        <h4 class="text-white mb-4">Software Design</h4>
                        <p class="text-white-50 mb-2">
                            We approached the project in two parts: first generate sounds that sound musical, then implement key detection. 
                        </p>
                        <p class="text-white-50 mb-2">
                            To generate sound, we used an FM synthesis program created by Professor Land.<sup>(1)</sup> FM synthesis is similar to Direct 
                            Digital Synthesis which we used in the Cricket Chirp Synthesis lab, but it produces more musical tones. Professor Land's 
                            program output and cycled through the seven notes in a C scale. 
                        </p>
                        <p class="text-white-50 mb-2">
                            We built upon this program to fit our needs by adding two random number generators: one to select which frequency to 
                            play next (note_SM()) and another to select the time-length of that note (rand_note_length()). As stated in the background math/algorithms section, we used a 
                            random number generator created by Deemo Chen who is also in this class.<sup>3</sup>
                            Here is a code snippet from the FM Synthesis thread showing how the outputs from these RNGS decide the next note that will be played:
                        </p>
                        <img class="img-fluid" src="assets/img/note_SM_called.jpg" alt="..." /> 
                        <p class="text-white-50 mb-2">
                            To play around with different keys, tempos, and weights, we added a serial input interface for 
                            these values. Professor Land's original code outputs the C scale at a tempo of about 80 beats per minute (BPM), and we were
                            able to multiply the lengths of the FM Synthesis time parameters by a factor of the inputted tempo. There are 12 different 
                            major keys, and the only way to be able to "pick" between them is with a long if-else statement. Based on the input key signature, 
                            the if statement associated with that key would assign each of the elements in the frequency array with the appropriate frequencies 
                            in that key. Here is a snippet of two of those 12 cases. 
                        </p>
                        <img class="img-fluid" src="assets/img/set_key_ifstatement.jpg" alt="..." /> 
                        <p class="text-white-50 mb-2">
                            At this point, the Jambot was outputting random songs with specified tempos, keys, and weights. We were ready to move on to key detection.
                        </p>
                        <p class="text-white-50 mb-2">
                            We thought about the Cricket Chirp Synthesis Lab, and how FFT was used to detect other cricket chirps at specific frequencies. 
                            We tried to use the working FFT code from the first lab and add it to our now working Jambot code, but it proved to be challenging. 
                            Professor Land's FM synthesis program already had FFT capabilities, but it calculated the FFT of the output frequency 
                            instead of any signals from a microphone. Professor Land's code did not use a microphone at all. Furthermore, the FFT 
                            algorithm already in the FM synthesis program used fix12 and fix14 data types, while we had been using fix15 all semester. 
                            We would run into dozens of data type and variable name errors several times and end up scrapping our progress and returning 
                            to where we had started before trying to combine code. 
                        </p>
                        <p class="text-white-50 mb-2">
                            We spent about a week trying to figure out how to combine the code or alter the FFT functions that were already 
                            in the FM synthesis program, without much luck. Finally, we realized that Professor Land had another program 
                            which did use a microphone and computed FFT on the microphone data to detect frequencies, using the same data 
                            types that we had in our FM synthesis program.<sup>1</sup> It even came with a VGA display that displayed the current heard 
                            frequency and its spectrum diagram. At this point, we had a lot of practice with trying to combine new FFT functions 
                            to replace the original ones in our FM synthesis program, so we were able to successfully integrate the programs almost immediately. 
                        </p>
                        <p class="text-white-50 mb-2">
                            Now frequency detection worked, and we needed to come up with a way to use that data to determine a pattern, 
                            or a key signature. To approach this task, we thought about how people with perfect pitch might determine 
                            keys of songs. 
                        </p>
                        <p class="text-white-50 mb-2">
                            We understand limited music theory, but we know that there is a pattern that in simpler songs, root notes, or 
                            the "name" of the key, are frequently played throughout the song. In Cornell's Alma Mater, the root note is the start note 
                            of 3 of the 4 phrases, and the last note of 2 of the 4 phrases.<sup>4</sup> Other common notes in simple songs are thirds, fifths, and 
                            sevenths. We used this "common note" observation to implement our key detection function. 
                        </p>
                        <p class="text-white-50 mb-2">
                            In the FFT function, we detect the highest peak bin. When the maximum magnitude frequency is the same 
                            frequency two times in a row, we add that frequency to an array. We wait for duplicate detections to limit 
                            noise being detected. When 15 elements have been stored in this array, we move to the Key Detection Function. 
                            This function will compare the collected frequencies to the frequencies in several guessed key signatures. First, 
                            each of the frequencies in the detected array are normalized to within a range of a specific octave for comparison purposes. 
                            We utilized the fact that all octave jumps are related by a factor of two i.e. C4 is twice the amount of Hertz as C3. Also, 
                            any frequencies lower than 60 Hz or higher than 4200 Hz are discarded. For reference, middle C is about 261 Hz. 
                        </p>
                        <p class="text-white-50 mb-2">
                            With this normalized array, we find the mode. Then, we guess that the mode is the root note of the 
                            key and compare all of the elements in the array to that key. If it is not a match, we move onto the fifth. 
                            If that is not a match, then we try the seventh. For example, if C is the mode then we first try the key of C, 
                            then the key of F, then the key of Db. When a match is detected, the program immediately enters the song output that 
                            we implemented before. If a match is not detected from any of these three tries, then the program goes back to the FFT 
                            function and starts the detected notes array filling process over again.
                        </p>
                        <p class="text-white-50 mb-2">
                            While testing this comparison method, we realized that frequencies from the FFT function to be as 
                            accurate as possible. Initially, the code used 512 bins, and there were a few frequencies which were in 
                            between two different notes. To make the frequency divisions more precise, we increased the number of bins to 2048. 
                            This slowed down the process quite a bit, which was visually observed by how much the VGA display was suddenly lagging. 
                            However, to the user, the process does not take very long so this justified the longer computation time. 
                        </p>
                        <img class="img-fluid" src="assets/img/key_detection_SM.jpg" alt="..." /> 

                        <h4 class="text-white mb-4">Hardware Design</h4>
                        <p class="text-white-50 mb-2">
                            Since the physical needs of this project were identical to those of the Cricket Chirp Synthesis lab 
                            (Lab 1), we used the same circuit design.<sup>5</sup> It is a simple circuit and could easily and cheaply be rebuilt.                        
                        </p>
                        <img class="img-fluid" src="assets/img/full_circuit_diagram.jpg" alt="..." /> 

                    </div>
                </div>
            </div>
        </section> -->

        <!--Results-->
        <!-- <section class="projects-section bg-light" id="results">
            <div class="container px-4 px-lg-5"> -->
                <!-- Featured Project Row-->
                <!-- <div class="row gx-0 mb-4 mb-lg-5 align-items-center">
                        <div class="featured-text text-center text-lg-left">
                            <h4>Results</h4>
                            <p class="text-black-50 mb-10">Over the course of four weeks, with discussion with staff, 
                                we were able to adjust and achieve our goals. Our conceptual system was composed of many components that
                                we had to implement. With the FM synthesis and FFT programs already implemented, we created a method for key detection. 
                                We also implemented random generators for which note of the heard key would be played and for what duration. To create 
                                different rhythms and create better matching ones, probability weights for note and duration were created and allowed to be 
                                inputted by the user. In addition, this latter feature would take into account the beats per measure. Additionally, an input 
                                for tempo was created, and was used as an indicator for whether longer or shorter notes would be favored at faster or higher 
                                tempoed songs, respectively. 
                            </p>
                            <p class="text-black-50 mb-10">With each implementation, the system was tested through a variety of ways.  For example, since 
                                we wanted our Jambot to sound like a musical instrument, parameters of the FM synthesis program were modified and tested 
                                through audio output. A problem that surfaced was that the notes sounded choppy and did not seem to be "played" the entire 
                                duration, with pauses between notes. Removing a yield function within the protothread_fm fixed this problem, as there was a 
                                noticeable auditory difference. When initially working with Bruce Land's code and troubleshooting, we heavily relied on the 
                                serial interface as well as the VGA frequency spectrum display. Features such as the probability inputs, random generator 
                                output, and additional notes played for a certain duration to a list were tested with print statements and the serial interface 
                                as well. Each note held for a certain duration (that also was added to a list) were printed to the serial interface. The detected 
                                key or failure of key detection were added as messages to the serial interface as well.
                            </p>
                            <p class="text-black-50 mb-10">While there was testing for features of the program as it was built, there was also separate testing 
                                for the completed system as a whole. To test the system, we played a variety of songs of known key, tempo (beats per measure), 
                                and genre. When first testing the system we noticed two things: one, our system didn't always rhythmically match the song, 
                                and two, our system took a much longer time to detect the key of faster tempo songs. We were able to notice this by listening 
                                to audio output, as well as watching what frequencies were held for a certain time and added to the list. Initially, for a note 
                                to be considered held for a duration of time, three beats of the same frequency had to be detected; this was changed to two beats 
                                to reduce the time needed for a key to be detected for faster songs. Even though we were able to achieve all of the aforementioned 
                                features, we wanted the JamBot to sound rhythmic or harmonious as it played along with a chosen song. To do this, we designed a few 
                                versions of the probability weights. By "version," each key had weights that were changed to sound differently. For example, by 
                                referencing sheet music, jazz-like weights were created. The other versions were an "equal" weights implementation, where 
                                probabilities were the same across all keys, and a version that could be inputted by the user. To correct for faster tempo songs, 
                                a correlation program between tempo and note duration was created. 
                            </p>
                            <p class="text-black-50 mb-10">
                                With these modifications, there was a noticeable effect on the system. For example, although there was still a slight pause 
                                between FM synthesis notes, it was not very noticeable and the JamBot output sounded like an actual instrument. The change from 
                                detecting three beats of the same frequency to two beats also sped up the time it took for a key 
                                to be detected. We found that most songs took from 10 seconds to 1 minute for the key to be detected; longer durations were noticed 
                                for songs with more accidentals or notes that are half steps above or below a note of the key. Detection of the frequencies held for
                                 a number of beats were detected and printed to the serial interface immediately. Once the list reached the required minimum number 
                                 of detected notes, the system took about less than a second to start playing notes of a certain key or, in case of key detection 
                                 failure, relistening for more notes. Accuracy of notes detected was ensured by using the VGA frequency display from Bruce Land's 
                                 code, and for notes played, frequencies were hardcoded from online sources. The tempo, note duration, and correlation between 
                                 these features was tested by using a metronome and manually adjusting the calculated tempo variable in the code.
                            </p>
                            <p class="text-black-50 mb-10">
                                The JamBot system relies mostly on software implementations. Any hardware additions were insulated or properly physically 
                                isolated from one another on the circuit. The circuit itself relied on voltage from lab computers to the Raspberry Pi pico. 
                                Filtering also occurred through software functions. Therefore, the system is safe to use by most users. For ease of use, the 
                                serial interface was a key component. One key feature was a menu of default probability weights that a user could choose from- 
                                "jazzy weights," "equal weights," or "create new weights." Other messages were prompted to the user to input values such as for 
                                tempo. By having a series of messages and values that could be entered with the lab computer keyboard, adjustable parameters could 
                                easily be changed. For a song to be detected, the user would only need to choose a song on their phone and have the phone positioned 
                                near the microphone of the circuit. To reset the system and play a new song, the buttons of the USB extension of the lab computer 
                                would need to be powered off and back on. As such, the system does not have many components that the user has to change, and if 
                                the components did change, the user could easily adjust them.
                            </p>
                        </div>
                </div>
            </div>
        </section> -->

         <!-- Conclusion-->
         <!-- <section class="about-section text-center" id="conclusion">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-lg-8">
                        <h2 class="text-white mb-4">Conclusion</h2>
                        <p class="text-white-50 mb-3">
                            When we first envisioned and suggested our project, our idea was to have the pico reproduce a jazz solo. 
                            Given a key and tempo through serial communication, using a microphone and FFT, the Pico would be able to 
                            determine which pitches are being played and which key those pitches have in common. We also planned to start 
                            the solo production with two random number generators: one that assigns the next note to play and another to 
                            determine how long to play that note. To make the solos sound less random, we could write a Machine Learning 
                            program (Markov model) with classic jazz solos on another computer. The Pico could then learn which "steps" 
                            (relationships between successive notes) sound better.
                        </p>
                        <p class="text-white-50 mb-3">
                            Though our final system wasn't necessarily the exact same as what we initially thought, we were still able to 
                            produce a successful system that met and exceeded our expectations. In the end, we created a system that took 
                            in a musical input, then using FFT, the system was able to detect the key the input was in and output a succession 
                            of random notes that had the same tempo as our input song. There were ideas from our original design that remained 
                            in our final design, we still input our tempo, we still had our Pico determine the key based on the pitches that
                            were heard, and we still had notes be randomly played in succession. There were also ideas that were changed and 
                            removed that either elevated or simplified our design. For example, instead of the notes in succession played being
                            fully random, each pitch within the key was given weights, where each weight determined the likelihood of the note
                            playing. Thus we were able to manipulate the weights ourselves to hear what sounded best with a song. This feature 
                            also replaced the need for the machine learning algorithm we initially proposed. Additionally, instead of the length 
                            of each note being at random, the note length was dependent on the song. Our system would replicate the note length 
                            of the song. If the song were playing a half note, the system would play a half note and that was consistent for all notes. 
                        </p>
                        <p class="text-white-50 mb-3">
                            In order to implement our system, the basis of our code was developed using code from Bruce Land's ECE4760 website. 
                            We drew our inspiration from Bruce's use of FM sound synthesis in order to reproduce the piano sound, as well as his 
                            building of the FFT in order to obtain data acquired by the Pico. Other than Bruce's code which is on a public domain, 
                            the rest was built by us. So it'll likely be able to be patented. 
                        </p>
                        <p class="text-white-50 mb-3">
                            There's a lot we could expand upon with this project. For example, we could try again to make sounds smoother with a 
                            Markov model using machine learning. An issue that we ran into during the lab was that for songs that had accidentals 
                            or a faster tempo, the system took longer to pick up the correct key. Perhaps implementing the machine learning program 
                            would further improve upon those issues in the future. Another place where we could improve is our system works great with instrumentals, 
                            but not the best with songs with lyrics. So we could also change our system by refining it to accommodate songs with lyrics. 
                            Given that the microphone is pretty sensitive, maybe we could change it to one that is less influenced by outside noise. 
                            Lastly, we decided that our system would output piano keys rather than guitar keys since piano was both more jazz-like, 
                            and was already implemented in Bruce's code. To further expand on that, we could have our system detect what instrument 
                            is playing and play back the song with the same instrument. 
                        </p>
                    </div>
                </div>
            </div>
        </section> -->
        <!-- Demo-->
        <!-- <section class="about-section text-center" id="demo">
        <div class="container px-4 px-lg-5">
            <div class="row gx-4 gx-lg-5 justify-content-center">
                <div class="col-lg-8">
                    <h2 class="text-white mb-4">Final Demo</h2>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/kAoxX1GrPYs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>
            </div>
        </div>
    </section> -->

           <!--Appendices-->
           <!-- <section class="projects-section bg-light" id="appendices">
            <div class="container px-4 px-lg-5"> -->
                <!-- Featured Project Row-->
                <!-- <div class="row gx-0 mb-4 mb-lg-5 align-items-center">
                        <div class="featured-text text-center text-lg-left">
                            <h4>Appendices</h4>

                            <h5>Appendix A: Permissions</h5>
                            <p class="text-black-50 mb-10"> The group approves this report for inclusion on the course website. 
                            </p>
                            <p class="text-black-50 mb-10"> The group approves the video for inclusion on the course youtube channel. 
                            </p>
                            
                            <h5>Appendix B: References</h5>

                            <p class="text-black-50 mb-10"> 1.  Land, B. (2011, September 11). ECE4760 PIC32 sound. Electrical and Computer Engineering | Electrical and Computer Engineering; ECE 4760 -  Bruce Land. https://people.ece.cornell.edu/land/courses/ece4760/PIC32/index_sound_synth.html 
                            </p>
                            <p class="text-black-50 mb-10"> 2. Fourier Transform - Definition, Formula, Properties, Applications and Examples. (2022, June 22). BYJUS; BYJU'S. https://byjus.com/maths/fourier-transform/ 
                            </p>
                            <p class="text-black-50 mb-10"> 3. Chen, D. (2022, October 2). RP2040 Randomness and Ring Oscillator - DeemOcean. DeemOcean; Deemo Yizhou Chen Observatory. https://deemocean.com/2022/10/02/rp2040-randomness-and-ring-oscillator/ 

                            </p>
                            <p class="text-black-50 mb-10"> 4. Alma Mater - Sidney Cox Library of Music and Dance. (n.d.). Sidney Cox Library of Music and Dance. Retrieved December 13, 2022, from https://music.library.cornell.edu/alma-mater/ 

                            </p>
                            <p class="text-black-50 mb-10"> 5. Adams, H. (n.d.-b). Crickets. Index; ECE 4760 - Van Hunter Adams. Retrieved December 13, 2022, from https://vanhunteradams.com/Pico/Cricket/Crickets.html 

                            </p>

                            <h5>Appendix C: Specific Tasks</h5>
                            <p class="text-black-50 mb-10"> We all put in equal work in terms of debugging and thinking of how to implement the program. Wanda helped with the music theory side of things,
                                Kaitlyn wrote and turned in all of the weekly checkpoints, and Nia tested the hardware and the checkpoints along the way.
                            </p>

                        </div>
                </div>
            </div>
        </section>
        <section class="projects-section bg-light" id="appendices">
            <div class="featured-text text-center text-lg-left">
                <h5>Appendix D: Commented Code</h5>
            </div> -->
           <!-- HTML generated using hilite.me -->
           \
        <!-- Footer-->
        <footer class="footer bg-black small text-center text-white-50"><div class="container px-4 px-lg-5">Credit to Bootstrap's library of free HTML theme for the template of this website. 
        
        </div>
        <div class="container px-4 px-lg-5">Content by Wanda Field. ECE 4160 S23.</div></footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
        <!-- * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *-->
        <!-- * *                               SB Forms JS                               * *-->
        <!-- * * Activate your form at https://startbootstrap.com/solution/contact-forms * *-->
        <!-- * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *-->
        <script src="https://cdn.startbootstrap.com/sb-forms-latest.js"></script>
    </body>
</html>
